{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Data cleaning and Data engineering"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","23/11/16 19:08:37 INFO SparkEnv: Registering MapOutputTracker\n","23/11/16 19:08:37 INFO SparkEnv: Registering BlockManagerMaster\n","23/11/16 19:08:37 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n","23/11/16 19:08:37 INFO SparkEnv: Registering OutputCommitCoordinator\n","/usr/lib/spark/python/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n","  warnings.warn(\n"]}],"source":["# Uncomment the following lines if you are using Windows!\n","# import findspark\n","# findspark.init()\n","# findspark.find()\n","\n","import pyspark\n","\n","from pyspark.sql import SparkSession\n","from pyspark import SparkContext, SQLContext\n","\n","appName = \"Big Data Analytics\"\n","master = \"local\"\n","\n","# Create Configuration object for Spark.\n","conf = pyspark.SparkConf()\\\n","    .set('spark.driver.host','127.0.0.1')\\\n","    .setAppName(appName)\\\n","    .setMaster(master)\\\n","    .set('spark.jars', 'gs://dataproc-staging-us-central1-159964990471-2n8oqiw8/postgresql-42.6.0.jar')\n","\n","# Create Spark Context with the new configurations rather than relying on the default one\n","sc = SparkContext.getOrCreate(conf=conf)\n","\n","# You need to create SQL Context to conduct some database operations like what we will see later.\n","sqlContext = SQLContext(sc)\n","\n","# If you have SQL context, you create the session from the Spark Context\n","spark = sqlContext.sparkSession.builder.getOrCreate()\n","\n","# df_train = spark.read.csv(\"train70_reduced.csv\" ,header=True, inferSchema= True)\n","# df_test = spark.read.csv(\"test30_reduced.csv\", header=True, inferSchema=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Loading data from Cloud bucket and the Postgres on cloud"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df_train = spark.read.csv(\"gs://dataproc-staging-us-central1-159964990471-2n8oqiw8/train70_reduced.csv\" ,header=True, inferSchema= True)\n","df_test = spark.read.csv(\"gs://dataproc-staging-us-central1-159964990471-2n8oqiw8/test30_reduced.csv\", header=True, inferSchema=True)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from pyspark.sql.functions import lit\n","\n","df_train = df_train.withColumn('Train', lit(1))\n","df_test = df_test.withColumn('Train', lit(0))"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/11/16 19:08:49 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n","                                                                                \r"]}],"source":["db_properties={}\n","#update your db username\n","db_properties['username']=\"postgres\"\n","#update your db password\n","db_properties['password']=\"18763kebjeseaya\"\n","#make sure you got the right port number here\n","db_properties['url']= \"jdbc:postgresql://34.136.81.58/postgres\"\n","#make sure you had the Postgres JAR file in the right location\n","db_properties['driver']=\"org.postgresql.Driver\"\n","db_properties['table']= \"mqtt\"\n","\n","\n","df_train.write.format(\"jdbc\")\\\n",".mode(\"overwrite\")\\\n",".option(\"url\", db_properties['url'])\\\n",".option(\"dbtable\", db_properties['table'])\\\n",".option(\"user\", db_properties['username'])\\\n",".option(\"password\", db_properties['password'])\\\n",".option(\"Driver\", db_properties['driver'])\\\n",".save()\n","\n","df_test.write.format(\"jdbc\")\\\n",".mode(\"append\")\\\n",".option(\"url\", db_properties['url'])\\\n",".option(\"dbtable\", db_properties['table'])\\\n",".option(\"user\", db_properties['username'])\\\n",".option(\"password\", db_properties['password'])\\\n",".option(\"Driver\", db_properties['driver'])\\\n",".save()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-RECORD 0--------------------------------\n"," tcp.flags                  | 0x00000018 \n"," tcp.time_delta             | 0.998867   \n"," tcp.len                    | 10         \n"," mqtt.conack.flags          | 0          \n"," mqtt.conack.flags.reserved | 0.0        \n"," mqtt.conack.flags.sp       | 0.0        \n"," mqtt.conack.val            | 0.0        \n"," mqtt.conflag.cleansess     | 0.0        \n"," mqtt.conflag.passwd        | 0.0        \n"," mqtt.conflag.qos           | 0.0        \n"," mqtt.conflag.reserved      | 0.0        \n"," mqtt.conflag.retain        | 0.0        \n"," mqtt.conflag.uname         | 0.0        \n"," mqtt.conflag.willflag      | 0.0        \n"," mqtt.conflags              | 0          \n"," mqtt.dupflag               | 0.0        \n"," mqtt.hdrflags              | 0x00000030 \n"," mqtt.kalive                | 0.0        \n"," mqtt.len                   | 8.0        \n"," mqtt.msg                   | 32         \n"," mqtt.msgid                 | 0.0        \n"," mqtt.msgtype               | 3.0        \n"," mqtt.proto_len             | 0.0        \n"," mqtt.protoname             | 0          \n"," mqtt.qos                   | 0.0        \n"," mqtt.retain                | 0.0        \n"," mqtt.sub.qos               | 0.0        \n"," mqtt.suback.qos            | 0.0        \n"," mqtt.ver                   | 0.0        \n"," mqtt.willmsg               | 0.0        \n"," mqtt.willmsg_len           | 0.0        \n"," mqtt.willtopic             | 0.0        \n"," mqtt.willtopic_len         | 0.0        \n"," target                     | legitimate \n"," Train                      | 1          \n","only showing top 1 row\n","\n"]}],"source":["df = sqlContext.read.format(\"jdbc\")\\\n","    .option(\"url\", db_properties['url'])\\\n","    .option(\"dbtable\", db_properties['table'])\\\n","    .option(\"user\", db_properties['username'])\\\n","    .option(\"password\", db_properties['password'])\\\n","    .option(\"Driver\", db_properties['driver'])\\\n","    .load()\n","\n","df.show(1, vertical=True)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["df_train = df.filter(df.Train == 1)\n","df_test = df.filter(df.Train == 0)\n","\n","#dropping the train column\n","df_train = df_train.drop('Train')\n","df_test = df_test.drop('Train')"]},{"cell_type":"markdown","metadata":{},"source":["### Renaming cols"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["cols = df_train.columns\n","\n","for column in cols:\n","    new_column = column.replace('.', '_')\n","    df_train = df_train.withColumnRenamed(column, new_column)\n","    \n","# df_train.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["### Creating Output label column"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from pyspark.sql.functions import when\n","from pyspark.sql.functions import col\n","df_with_target = df_train.withColumn('label', when(col('target') == 'slowite', 0).when(col('target') == 'bruteforce', 1).\\\n","                               when(col('target') == 'flood', 2).when(col('target') == 'malformed', 3).when(col('target')\\\n","                             == 'dos', 4).when(col('target') == 'legitimate', 5).otherwise(6)).drop('target')\n","# df_with_target.show(1, vertical=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Deleting null records"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 7:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["-RECORD 0-------------------------\n"," tcp_flags                  | 0   \n"," tcp_time_delta             | 0   \n"," tcp_len                    | 0   \n"," mqtt_conack_flags          | 0   \n"," mqtt_conack_flags_reserved | 0   \n"," mqtt_conack_flags_sp       | 0   \n"," mqtt_conack_val            | 0   \n"," mqtt_conflag_cleansess     | 0   \n"," mqtt_conflag_passwd        | 0   \n"," mqtt_conflag_qos           | 0   \n"," mqtt_conflag_reserved      | 0   \n"," mqtt_conflag_retain        | 0   \n"," mqtt_conflag_uname         | 0   \n"," mqtt_conflag_willflag      | 0   \n"," mqtt_conflags              | 0   \n"," mqtt_dupflag               | 0   \n"," mqtt_hdrflags              | 0   \n"," mqtt_kalive                | 0   \n"," mqtt_len                   | 0   \n"," mqtt_msg                   | 0   \n"," mqtt_msgid                 | 0   \n"," mqtt_msgtype               | 0   \n"," mqtt_proto_len             | 0   \n"," mqtt_protoname             | 0   \n"," mqtt_qos                   | 0   \n"," mqtt_retain                | 0   \n"," mqtt_sub_qos               | 0   \n"," mqtt_suback_qos            | 0   \n"," mqtt_ver                   | 0   \n"," mqtt_willmsg               | 0   \n"," mqtt_willmsg_len           | 0   \n"," mqtt_willtopic             | 0   \n"," mqtt_willtopic_len         | 0   \n"," label                      | 0   \n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["from pyspark.sql.functions import *\n","null_counts_plays_df = df_with_target.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) \\\n","                        for c in df_with_target.columns])\n","null_counts_plays_df.show(truncate=False, vertical=True)\n","\n","# No rows with null values"]},{"cell_type":"markdown","metadata":{},"source":["### Checking constraints"]},{"cell_type":"markdown","metadata":{},"source":["1. `tcp_time_delta` : Must be > 0, if not set it to 0.\n","2. [`tcp_len`, `mqtt_len`, `mqtt_proto_len`, `mqtt_willmsg_len`, `mqtt_willtopic_len`] --> Must be >= 0\n","3. Cols with flag information must be of the format '0x000000xx'. These include [`tcp_flags`, `mqtt_conack_flags`, `mqtt_conflags`, `mqtt_hdrflags`]"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------+-------+--------+--------------+----------------+------------------+\n","|tcp_time_delta|tcp_len|mqtt_len|mqtt_proto_len|mqtt_willmsg_len|mqtt_willtopic_len|\n","+--------------+-------+--------+--------------+----------------+------------------+\n","|             1|      0|       0|             0|               0|                 0|\n","+--------------+-------+--------+--------------+----------------+------------------+\n","\n"]}],"source":["# Checking cols with > 0 condition\n","\n","cols_non_negative = ['tcp_time_delta', 'tcp_len', 'mqtt_len', 'mqtt_proto_len', 'mqtt_willmsg_len', 'mqtt_willtopic_len']\n","from pyspark.sql.functions import *\n","df_with_target.select([count(when(col(c) < 0, c)).alias(c) for c in cols_non_negative]).show()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Drop that record which has negative value in tcp_time_delta column\n","df_with_target = df_with_target.filter(df_with_target.tcp_time_delta >= 0)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------+-----------------+-------------+-------------+\n","|tcp_flags|mqtt_conack_flags|mqtt_conflags|mqtt_hdrflags|\n","+---------+-----------------+-------------+-------------+\n","|        0|           229429|       229428|        87052|\n","+---------+-----------------+-------------+-------------+\n","\n"]}],"source":["# Checking for the flag columns constraints\n","\n","cols_with_hex = ['tcp_flags', 'mqtt_conack_flags', 'mqtt_conflags', 'mqtt_hdrflags']\n","df_with_target.select([count(when(col(c) < 10, c)).alias(c) for c in cols_with_hex]).show()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Out of ~230,000 entries ~229,000 entries in mqtt_conack_flags and mqtt_conflags are not in hex format just (0).\n","# I will drop these two columns as they are not of much use to us.\n","# But for mqtt_hdrflags : ~ 37% of the entries are not in hex format.\n","# We could either 1 hot encode them or treat the entire col as binary column.\n","# 37% seems too big to simply drop the non hex entries.\n","# So I will 1 hot encode the column\n","\n","df_with_target_constraints_handled = df_with_target.drop('mqtt_conack_flags', 'mqtt_conflags')"]},{"cell_type":"markdown","metadata":{},"source":["### Investigating which cols are not useful to us."]},{"cell_type":"markdown","metadata":{},"source":["### (1) Deleting columns with only 1 unique value"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 16:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["-RECORD 0---------------------------\n"," tcp_flags                  | 8     \n"," tcp_time_delta             | 8954  \n"," tcp_len                    | 723   \n"," mqtt_conack_flags_reserved | 1     \n"," mqtt_conack_flags_sp       | 1     \n"," mqtt_conack_val            | 2     \n"," mqtt_conflag_cleansess     | 2     \n"," mqtt_conflag_passwd        | 2     \n"," mqtt_conflag_qos           | 1     \n"," mqtt_conflag_reserved      | 1     \n"," mqtt_conflag_retain        | 1     \n"," mqtt_conflag_uname         | 2     \n"," mqtt_conflag_willflag      | 1     \n"," mqtt_dupflag               | 2     \n"," mqtt_hdrflags              | 14    \n"," mqtt_kalive                | 7     \n"," mqtt_len                   | 91    \n"," mqtt_msg                   | 35695 \n"," mqtt_msgid                 | 9813  \n"," mqtt_msgtype               | 11    \n"," mqtt_proto_len             | 2     \n"," mqtt_protoname             | 2     \n"," mqtt_qos                   | 2     \n"," mqtt_retain                | 2     \n"," mqtt_sub_qos               | 1     \n"," mqtt_suback_qos            | 1     \n"," mqtt_ver                   | 2     \n"," mqtt_willmsg               | 1     \n"," mqtt_willmsg_len           | 1     \n"," mqtt_willtopic             | 1     \n"," mqtt_willtopic_len         | 1     \n"," label                      | 6     \n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["from pyspark.sql.functions import col, countDistinct\n","\n","unique_values_count = df_with_target_constraints_handled.agg(*(countDistinct(col(c)).alias(c)\\\n","                                         for c in df_with_target_constraints_handled.columns))\n","unique_values_count.show(vertical=True)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["['mqtt_conack_flags_reserved', 'mqtt_conack_flags_sp', 'mqtt_conflag_qos', 'mqtt_conflag_reserved', 'mqtt_conflag_retain', 'mqtt_conflag_willflag', 'mqtt_sub_qos', 'mqtt_suback_qos', 'mqtt_willmsg', 'mqtt_willmsg_len', 'mqtt_willtopic', 'mqtt_willtopic_len']\n","['tcp_flags', 'tcp_time_delta', 'tcp_len', 'mqtt_conack_val', 'mqtt_conflag_cleansess', 'mqtt_conflag_passwd', 'mqtt_conflag_uname', 'mqtt_dupflag', 'mqtt_hdrflags', 'mqtt_kalive', 'mqtt_len', 'mqtt_msg', 'mqtt_msgid', 'mqtt_msgtype', 'mqtt_proto_len', 'mqtt_protoname', 'mqtt_qos', 'mqtt_retain', 'mqtt_ver', 'label']\n"]}],"source":["# There are some cols with only 1 unique value, lets see what they are then drop them\n","\n","cols_to_drop = [column for column in unique_values_count.columns if unique_values_count.collect()[0][column] == 1]\n","print(cols_to_drop)\n","\n","df_with_target_constraints_handled = df_with_target_constraints_handled.drop(*cols_to_drop)\n","print(df_with_target_constraints_handled.columns)"]},{"cell_type":"markdown","metadata":{},"source":["### (2) Deleting highly correleated columns"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["['tcp_time_delta',\n"," 'tcp_len',\n"," 'mqtt_conack_val',\n"," 'mqtt_conflag_cleansess',\n"," 'mqtt_conflag_passwd',\n"," 'mqtt_conflag_uname',\n"," 'mqtt_dupflag',\n"," 'mqtt_kalive',\n"," 'mqtt_len',\n"," 'mqtt_msgid',\n"," 'mqtt_msgtype',\n"," 'mqtt_proto_len',\n"," 'mqtt_qos',\n"," 'mqtt_retain',\n"," 'mqtt_ver']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# To find the numeric cols in the dataframe\n","numeric_features = [t[0] for t in df_with_target_constraints_handled.dtypes if t[1] != 'string']\n","# Don't want to include the label column\n","numeric_features.remove('label')\n","numeric_features"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tcp_time_delta</th>\n","      <th>tcp_len</th>\n","      <th>mqtt_conack_val</th>\n","      <th>mqtt_conflag_cleansess</th>\n","      <th>mqtt_conflag_passwd</th>\n","      <th>mqtt_conflag_uname</th>\n","      <th>mqtt_dupflag</th>\n","      <th>mqtt_kalive</th>\n","      <th>mqtt_len</th>\n","      <th>mqtt_msgid</th>\n","      <th>mqtt_msgtype</th>\n","      <th>mqtt_proto_len</th>\n","      <th>mqtt_qos</th>\n","      <th>mqtt_retain</th>\n","      <th>mqtt_ver</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>tcp_time_delta</th>\n","      <td>1.000000</td>\n","      <td>-0.006663</td>\n","      <td>-0.006295</td>\n","      <td>-0.009440</td>\n","      <td>-0.006333</td>\n","      <td>-0.006346</td>\n","      <td>-0.017258</td>\n","      <td>-0.004982</td>\n","      <td>-0.036230</td>\n","      <td>-0.046167</td>\n","      <td>0.287740</td>\n","      <td>-0.009440</td>\n","      <td>-0.037255</td>\n","      <td>-0.001860</td>\n","      <td>-0.009440</td>\n","    </tr>\n","    <tr>\n","      <th>tcp_len</th>\n","      <td>-0.006663</td>\n","      <td>1.000000</td>\n","      <td>-0.010199</td>\n","      <td>-0.012766</td>\n","      <td>-0.008432</td>\n","      <td>-0.008450</td>\n","      <td>0.153574</td>\n","      <td>-0.008053</td>\n","      <td>0.268786</td>\n","      <td>0.156510</td>\n","      <td>0.083720</td>\n","      <td>-0.012766</td>\n","      <td>0.265729</td>\n","      <td>0.008987</td>\n","      <td>-0.012766</td>\n","    </tr>\n","    <tr>\n","      <th>mqtt_conack_val</th>\n","      <td>-0.006295</td>\n","      <td>-0.010199</td>\n","      <td>1.000000</td>\n","      <td>-0.006508</td>\n","      <td>-0.004366</td>\n","      <td>-0.004375</td>\n","      <td>-0.015572</td>\n","      <td>-0.003435</td>\n","      <td>-0.031787</td>\n","      <td>-0.033830</td>\n","      <td>-0.001747</td>\n","      <td>-0.006508</td>\n","      <td>-0.029217</td>\n","      <td>-0.001283</td>\n","      <td>-0.006508</td>\n","    </tr>\n","    <tr>\n","      <th>mqtt_conflag_cleansess</th>\n","      <td>-0.009440</td>\n","      <td>-0.012766</td>\n","      <td>-0.006508</td>\n","      <td>1.000000</td>\n","      <td>0.670844</td>\n","      <td>0.672186</td>\n","      <td>-0.023120</td>\n","      <td>0.527816</td>\n","      <td>0.002574</td>\n","      <td>-0.050229</td>\n","      <td>-0.055534</td>\n","      <td>1.000000</td>\n","      <td>-0.043379</td>\n","      <td>-0.001905</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mqtt_conflag_passwd</th>\n","      <td>-0.006333</td>\n","      <td>-0.008432</td>\n","      <td>-0.004366</td>\n","      <td>0.670844</td>\n","      <td>1.000000</td>\n","      <td>0.998003</td>\n","      <td>-0.015510</td>\n","      <td>-0.002252</td>\n","      <td>-0.004970</td>\n","      <td>-0.033696</td>\n","      <td>-0.037255</td>\n","      <td>0.670844</td>\n","      <td>-0.029100</td>\n","      <td>-0.001278</td>\n","      <td>0.670844</td>\n","    </tr>\n","    <tr>\n","      <th>mqtt_conflag_uname</th>\n","      <td>-0.006346</td>\n","      <td>-0.008450</td>\n","      <td>-0.004375</td>\n","      <td>0.672186</td>\n","      <td>0.998003</td>\n","      <td>1.000000</td>\n","      <td>-0.015541</td>\n","      <td>-0.002257</td>\n","      <td>-0.005000</td>\n","      <td>-0.033763</td>\n","      <td>-0.037329</td>\n","      <td>0.672186</td>\n","      <td>-0.029159</td>\n","      <td>-0.001281</td>\n","      <td>0.672186</td>\n","    </tr>\n","    <tr>\n","      <th>mqtt_dupflag</th>\n","      <td>-0.017258</td>\n","      <td>0.153574</td>\n","      <td>-0.015572</td>\n","      <td>-0.023120</td>\n","      <td>-0.015510</td>\n","      <td>-0.015541</td>\n","      <td>1.000000</td>\n","      <td>-0.012203</td>\n","      <td>0.527227</td>\n","      <td>0.400831</td>\n","      <td>0.120460</td>\n","      <td>-0.023120</td>\n","      <td>0.532977</td>\n","      <td>-0.004559</td>\n","      <td>-0.023120</td>\n","    </tr>\n","    <tr>\n","      <th>mqtt_kalive</th>\n","      <td>-0.004982</td>\n","      <td>-0.008053</td>\n","      <td>-0.003435</td>\n","      <td>0.527816</td>\n","      <td>-0.002252</td>\n","      <td>-0.002257</td>\n","      <td>-0.012203</td>\n","      <td>1.000000</td>\n","      <td>-0.001207</td>\n","      <td>-0.026512</td>\n","      <td>-0.029312</td>\n","      <td>0.527816</td>\n","      <td>-0.022896</td>\n","      <td>-0.001006</td>\n","      <td>0.527816</td>\n","    </tr>\n","    <tr>\n","      <th>mqtt_len</th>\n","      <td>-0.036230</td>\n","      <td>0.268786</td>\n","      <td>-0.031787</td>\n","      <td>0.002574</td>\n","      <td>-0.004970</td>\n","      <td>-0.005000</td>\n","      <td>0.527227</td>\n","      <td>-0.001207</td>\n","      <td>1.000000</td>\n","      <td>0.568639</td>\n","      <td>0.259118</td>\n","      <td>0.002574</td>\n","      <td>0.988035</td>\n","      <td>0.002293</td>\n","      <td>0.002574</td>\n","    </tr>\n","    <tr>\n","      <th>mqtt_msgid</th>\n","      <td>-0.046167</td>\n","      <td>0.156510</td>\n","      <td>-0.033830</td>\n","      <td>-0.050229</td>\n","      <td>-0.033696</td>\n","      <td>-0.033763</td>\n","      <td>0.400831</td>\n","      <td>-0.026512</td>\n","      <td>0.568639</td>\n","      <td>1.000000</td>\n","      <td>0.375774</td>\n","      <td>-0.050229</td>\n","      <td>0.584469</td>\n","      <td>-0.009904</td>\n","      <td>-0.050229</td>\n","    </tr>\n","    <tr>\n","      <th>mqtt_msgtype</th>\n","      <td>0.287740</td>\n","      <td>0.083720</td>\n","      <td>-0.001747</td>\n","      <td>-0.055534</td>\n","      <td>-0.037255</td>\n","      <td>-0.037329</td>\n","      <td>0.120460</td>\n","      <td>-0.029312</td>\n","      <td>0.259118</td>\n","      <td>0.375774</td>\n","      <td>1.000000</td>\n","      <td>-0.055534</td>\n","      <td>0.226013</td>\n","      <td>0.009928</td>\n","      <td>-0.055534</td>\n","    </tr>\n","    <tr>\n","      <th>mqtt_proto_len</th>\n","      <td>-0.009440</td>\n","      <td>-0.012766</td>\n","      <td>-0.006508</td>\n","      <td>1.000000</td>\n","      <td>0.670844</td>\n","      <td>0.672186</td>\n","      <td>-0.023120</td>\n","      <td>0.527816</td>\n","      <td>0.002574</td>\n","      <td>-0.050229</td>\n","      <td>-0.055534</td>\n","      <td>1.000000</td>\n","      <td>-0.043379</td>\n","      <td>-0.001905</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mqtt_qos</th>\n","      <td>-0.037255</td>\n","      <td>0.265729</td>\n","      <td>-0.029217</td>\n","      <td>-0.043379</td>\n","      <td>-0.029100</td>\n","      <td>-0.029159</td>\n","      <td>0.532977</td>\n","      <td>-0.022896</td>\n","      <td>0.988035</td>\n","      <td>0.584469</td>\n","      <td>0.226013</td>\n","      <td>-0.043379</td>\n","      <td>1.000000</td>\n","      <td>-0.008554</td>\n","      <td>-0.043379</td>\n","    </tr>\n","    <tr>\n","      <th>mqtt_retain</th>\n","      <td>-0.001860</td>\n","      <td>0.008987</td>\n","      <td>-0.001283</td>\n","      <td>-0.001905</td>\n","      <td>-0.001278</td>\n","      <td>-0.001281</td>\n","      <td>-0.004559</td>\n","      <td>-0.001006</td>\n","      <td>0.002293</td>\n","      <td>-0.009904</td>\n","      <td>0.009928</td>\n","      <td>-0.001905</td>\n","      <td>-0.008554</td>\n","      <td>1.000000</td>\n","      <td>-0.001905</td>\n","    </tr>\n","    <tr>\n","      <th>mqtt_ver</th>\n","      <td>-0.009440</td>\n","      <td>-0.012766</td>\n","      <td>-0.006508</td>\n","      <td>1.000000</td>\n","      <td>0.670844</td>\n","      <td>0.672186</td>\n","      <td>-0.023120</td>\n","      <td>0.527816</td>\n","      <td>0.002574</td>\n","      <td>-0.050229</td>\n","      <td>-0.055534</td>\n","      <td>1.000000</td>\n","      <td>-0.043379</td>\n","      <td>-0.001905</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        tcp_time_delta   tcp_len  mqtt_conack_val  \\\n","tcp_time_delta                1.000000 -0.006663        -0.006295   \n","tcp_len                      -0.006663  1.000000        -0.010199   \n","mqtt_conack_val              -0.006295 -0.010199         1.000000   \n","mqtt_conflag_cleansess       -0.009440 -0.012766        -0.006508   \n","mqtt_conflag_passwd          -0.006333 -0.008432        -0.004366   \n","mqtt_conflag_uname           -0.006346 -0.008450        -0.004375   \n","mqtt_dupflag                 -0.017258  0.153574        -0.015572   \n","mqtt_kalive                  -0.004982 -0.008053        -0.003435   \n","mqtt_len                     -0.036230  0.268786        -0.031787   \n","mqtt_msgid                   -0.046167  0.156510        -0.033830   \n","mqtt_msgtype                  0.287740  0.083720        -0.001747   \n","mqtt_proto_len               -0.009440 -0.012766        -0.006508   \n","mqtt_qos                     -0.037255  0.265729        -0.029217   \n","mqtt_retain                  -0.001860  0.008987        -0.001283   \n","mqtt_ver                     -0.009440 -0.012766        -0.006508   \n","\n","                        mqtt_conflag_cleansess  mqtt_conflag_passwd  \\\n","tcp_time_delta                       -0.009440            -0.006333   \n","tcp_len                              -0.012766            -0.008432   \n","mqtt_conack_val                      -0.006508            -0.004366   \n","mqtt_conflag_cleansess                1.000000             0.670844   \n","mqtt_conflag_passwd                   0.670844             1.000000   \n","mqtt_conflag_uname                    0.672186             0.998003   \n","mqtt_dupflag                         -0.023120            -0.015510   \n","mqtt_kalive                           0.527816            -0.002252   \n","mqtt_len                              0.002574            -0.004970   \n","mqtt_msgid                           -0.050229            -0.033696   \n","mqtt_msgtype                         -0.055534            -0.037255   \n","mqtt_proto_len                        1.000000             0.670844   \n","mqtt_qos                             -0.043379            -0.029100   \n","mqtt_retain                          -0.001905            -0.001278   \n","mqtt_ver                              1.000000             0.670844   \n","\n","                        mqtt_conflag_uname  mqtt_dupflag  mqtt_kalive  \\\n","tcp_time_delta                   -0.006346     -0.017258    -0.004982   \n","tcp_len                          -0.008450      0.153574    -0.008053   \n","mqtt_conack_val                  -0.004375     -0.015572    -0.003435   \n","mqtt_conflag_cleansess            0.672186     -0.023120     0.527816   \n","mqtt_conflag_passwd               0.998003     -0.015510    -0.002252   \n","mqtt_conflag_uname                1.000000     -0.015541    -0.002257   \n","mqtt_dupflag                     -0.015541      1.000000    -0.012203   \n","mqtt_kalive                      -0.002257     -0.012203     1.000000   \n","mqtt_len                         -0.005000      0.527227    -0.001207   \n","mqtt_msgid                       -0.033763      0.400831    -0.026512   \n","mqtt_msgtype                     -0.037329      0.120460    -0.029312   \n","mqtt_proto_len                    0.672186     -0.023120     0.527816   \n","mqtt_qos                         -0.029159      0.532977    -0.022896   \n","mqtt_retain                      -0.001281     -0.004559    -0.001006   \n","mqtt_ver                          0.672186     -0.023120     0.527816   \n","\n","                        mqtt_len  mqtt_msgid  mqtt_msgtype  mqtt_proto_len  \\\n","tcp_time_delta         -0.036230   -0.046167      0.287740       -0.009440   \n","tcp_len                 0.268786    0.156510      0.083720       -0.012766   \n","mqtt_conack_val        -0.031787   -0.033830     -0.001747       -0.006508   \n","mqtt_conflag_cleansess  0.002574   -0.050229     -0.055534        1.000000   \n","mqtt_conflag_passwd    -0.004970   -0.033696     -0.037255        0.670844   \n","mqtt_conflag_uname     -0.005000   -0.033763     -0.037329        0.672186   \n","mqtt_dupflag            0.527227    0.400831      0.120460       -0.023120   \n","mqtt_kalive            -0.001207   -0.026512     -0.029312        0.527816   \n","mqtt_len                1.000000    0.568639      0.259118        0.002574   \n","mqtt_msgid              0.568639    1.000000      0.375774       -0.050229   \n","mqtt_msgtype            0.259118    0.375774      1.000000       -0.055534   \n","mqtt_proto_len          0.002574   -0.050229     -0.055534        1.000000   \n","mqtt_qos                0.988035    0.584469      0.226013       -0.043379   \n","mqtt_retain             0.002293   -0.009904      0.009928       -0.001905   \n","mqtt_ver                0.002574   -0.050229     -0.055534        1.000000   \n","\n","                        mqtt_qos  mqtt_retain  mqtt_ver  \n","tcp_time_delta         -0.037255    -0.001860 -0.009440  \n","tcp_len                 0.265729     0.008987 -0.012766  \n","mqtt_conack_val        -0.029217    -0.001283 -0.006508  \n","mqtt_conflag_cleansess -0.043379    -0.001905  1.000000  \n","mqtt_conflag_passwd    -0.029100    -0.001278  0.670844  \n","mqtt_conflag_uname     -0.029159    -0.001281  0.672186  \n","mqtt_dupflag            0.532977    -0.004559 -0.023120  \n","mqtt_kalive            -0.022896    -0.001006  0.527816  \n","mqtt_len                0.988035     0.002293  0.002574  \n","mqtt_msgid              0.584469    -0.009904 -0.050229  \n","mqtt_msgtype            0.226013     0.009928 -0.055534  \n","mqtt_proto_len         -0.043379    -0.001905  1.000000  \n","mqtt_qos                1.000000    -0.008554 -0.043379  \n","mqtt_retain            -0.008554     1.000000 -0.001905  \n","mqtt_ver               -0.043379    -0.001905  1.000000  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","correlation_matrix = df_with_target_constraints_handled.select(numeric_features).toPandas().corr()\n","correlation_matrix"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------\n","Correlation > 0.9 between mqtt_conflag_cleansess and mqtt_proto_len: 1.0\n","Correlation > 0.9 between mqtt_conflag_cleansess and mqtt_ver: 1.0\n","Correlation > 0.9 between mqtt_conflag_passwd and mqtt_conflag_uname: 0.9980032722174356\n","Correlation > 0.9 between mqtt_len and mqtt_qos: 0.9880353598330669\n","Correlation > 0.9 between mqtt_proto_len and mqtt_ver: 1.0\n","--------------------------------------------------------------------------\n"]}],"source":["print('--------------------------------------------------------------------------')\n","row_idx = -1\n","for index, row in correlation_matrix.iterrows():\n","    row_idx += 1\n","    col_idx = 0\n","    for column, value in row.items():\n","        if col_idx <= row_idx:\n","            col_idx += 1\n","            continue\n","        if value > 0.9 or value < -0.9:\n","            print(f'Correlation > 0.9 between {index} and {column}: {value}')\n","        col_idx += 1\n","print('--------------------------------------------------------------------------')"]},{"cell_type":"markdown","metadata":{},"source":["- So there is very high correlation (> 0.9) between \n","1. [`mqtt_conflag_cleansess`, `mqtt_proto_len`, `mqtt_ver`]\n","2. [`mqtt_conflag_passwd`, `mqtt_conflag_uname`] \n","3. [`mqtt_len`, `mqtt_qos`].\n","- So from these 3 categories we can drop all but one columns"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["high_corr_cols_to_drop = ['mqtt_conflag_cleansess', 'mqtt_proto_len', 'mqtt_conflag_passwd', 'mqtt_len']\n","df_with_target_constraints_handled_sval_high_corr_dropped = df_with_target_constraints_handled.drop(*high_corr_cols_to_drop)"]},{"cell_type":"markdown","metadata":{},"source":["### Further Analysis to find which cols will not contribute much"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 170:>                                                        (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["-RECORD 0----------------------------------\n"," tcp_flags          | 0.0                  \n"," tcp_time_delta     | 0.08778912651202521  \n"," tcp_len            | 0.3730994707442474   \n"," mqtt_conack_val    | 0.9956312649496492   \n"," mqtt_conflag_uname | 0.9956485326771299   \n"," mqtt_dupflag       | 0.9475794963024938   \n"," mqtt_hdrflags      | 0.3757975531631201   \n"," mqtt_kalive        | 0.9904250451141924   \n"," mqtt_msg           | 0.5237388083547482   \n"," mqtt_msgid         | 0.716770416930577    \n"," mqtt_msgtype       | 0.3757975531631201   \n"," mqtt_protoname     | 0.9904250451141924   \n"," mqtt_qos           | 0.8370056033792851   \n"," mqtt_retain        | 0.9996201099977106   \n"," mqtt_ver           | 0.9904250451141924   \n"," label              | 0.027805358175840077 \n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# To find what % of values in each col are 0\n","\n","from pyspark.sql.functions import lit, col, sum\n","zero_count_df = df_with_target_constraints_handled_sval_high_corr_dropped.select(\\\n","                [sum(when(col(c) == 0, 1).otherwise(0)/df_train.count()).alias(c)\\\n","                for c in df_with_target_constraints_handled_sval_high_corr_dropped.columns])\n","zero_count_df.show(vertical=True)"]},{"cell_type":"markdown","metadata":{},"source":["1. 99% values are 0 --> `mqtt_conack_val`, `mqtt_conflag_uname`, `mqtt_kalive`, `mqtt_protoname`, `mqtt_retain`, `mqtt_ver`.\n","2. I will be dropping these columns."]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["cols_99_percent_zero = [column for column in zero_count_df.columns if zero_count_df.collect()[0][column] > 0.99]\n","df_with_target_constraints_handled_sval_high_corr_99_percent_zero_dropped =\\\n","      df_with_target_constraints_handled_sval_high_corr_dropped.drop(*cols_99_percent_zero)"]},{"cell_type":"markdown","metadata":{},"source":["`mqtt_msg` col has a lot of numbers and strings values. This column can be dropped as well."]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["df_with_target_constraints_handled_sval_high_corr_99_percent_zero_dropped = \\\n","    df_with_target_constraints_handled_sval_high_corr_99_percent_zero_dropped.drop('mqtt_msg')"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- tcp_flags: string (nullable = true)\n"," |-- tcp_time_delta: double (nullable = true)\n"," |-- tcp_len: integer (nullable = true)\n"," |-- mqtt_dupflag: double (nullable = true)\n"," |-- mqtt_hdrflags: string (nullable = true)\n"," |-- mqtt_msgid: double (nullable = true)\n"," |-- mqtt_msgtype: double (nullable = true)\n"," |-- mqtt_qos: double (nullable = true)\n"," |-- label: integer (nullable = false)\n","\n"]}],"source":["df_with_target_constraints_handled_sval_high_corr_99_percent_zero_dropped.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["### Binary, Ordinal and Nominal Values"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["from pyspark.ml.feature import StringIndexer, OneHotEncoder\n","from pyspark.ml import Pipeline\n","\n","nominal_cols = ['tcp_flags', 'mqtt_hdrflags']\n","nominal_cols_string_indexed = [f'{col}_numeric' for col in nominal_cols]\n","nominal_cols_one_hot_encoded = [f'{col}_onehot' for col in nominal_cols]\n","\n","# 1. transform cols to numeric\n","stage_1 = StringIndexer(inputCols=nominal_cols, outputCols=nominal_cols_string_indexed)\n","\n","# 2. transform numeric cols to one hot encoded cols\n","stage_2 = OneHotEncoder(inputCols=stage_1.getOutputCols(), outputCols=nominal_cols_one_hot_encoded)\n","\n","pipeline = Pipeline(stages=[stage_1, stage_2])\n","\n","df_with_target_constraints_handled_sval_high_corr_99_percent_zero_dropped = pipeline.fit(df_with_target_constraints_handled_sval_high_corr_99_percent_zero_dropped)\\\n","    .transform(df_with_target_constraints_handled_sval_high_corr_99_percent_zero_dropped)\n","\n","# Now drop the original nominal cols and string indexed cols\n","\n","df_with_target_constraints_handled_sval_high_corr_99_percent_zero_dropped = \\\n","    df_with_target_constraints_handled_sval_high_corr_99_percent_zero_dropped.drop(*nominal_cols, *nominal_cols_string_indexed)"]},{"cell_type":"markdown","metadata":{},"source":["### Combining Features in a Vector"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["feature_list = df_with_target_constraints_handled_sval_high_corr_99_percent_zero_dropped.drop('label').columns"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# Now to combine all the features into a single vector\n","\n","from pyspark.ml.feature import VectorAssembler\n","vector_assembler = VectorAssembler(inputCols=feature_list, outputCol='vectorized_features')\n","df_with_assembled_features = vector_assembler.transform(df_with_target_constraints_handled_sval_high_corr_99_percent_zero_dropped)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>vectorized_features</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>(0.000288, 1460.0, 1.0, 4505.0, 3.0, 1.0, 0.0,...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>(0.000184, 14.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0,...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>(0.0004, 1460.0, 0.0, 4775.0, 3.0, 1.0, 0.0, 1...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>(0.999952, 14.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0,...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>(2.001151, 32760.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>78861</th>\n","      <td>(0.000898, 4.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, ...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>78862</th>\n","      <td>(0.000919, 4.0, 0.0, 4184.0, 4.0, 0.0, 1.0, 0....</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>78863</th>\n","      <td>(0.000269, 1460.0, 0.0, 5577.0, 3.0, 1.0, 0.0,...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>78864</th>\n","      <td>(1e-06, 102.0, 0.0, 3360.0, 3.0, 1.0, 1.0, 0.0...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>78865</th>\n","      <td>(0.000895, 28.0, 0.0, 3666.0, 4.0, 0.0, 1.0, 0...</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>78866 rows × 2 columns</p>\n","</div>"],"text/plain":["                                     vectorized_features  label\n","0      (0.000288, 1460.0, 1.0, 4505.0, 3.0, 1.0, 0.0,...      4\n","1      (0.000184, 14.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0,...      3\n","2      (0.0004, 1460.0, 0.0, 4775.0, 3.0, 1.0, 0.0, 1...      4\n","3      (0.999952, 14.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0,...      5\n","4      (2.001151, 32760.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0...      2\n","...                                                  ...    ...\n","78861  (0.000898, 4.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, ...      3\n","78862  (0.000919, 4.0, 0.0, 4184.0, 4.0, 0.0, 1.0, 0....      4\n","78863  (0.000269, 1460.0, 0.0, 5577.0, 3.0, 1.0, 0.0,...      4\n","78864  (1e-06, 102.0, 0.0, 3360.0, 3.0, 1.0, 1.0, 0.0...      4\n","78865  (0.000895, 28.0, 0.0, 3666.0, 4.0, 0.0, 1.0, 0...      4\n","\n","[78866 rows x 2 columns]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["df_with_assembled_features.select('vectorized_features', 'label').distinct().toPandas()"]},{"cell_type":"markdown","metadata":{},"source":["### Scaling"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>features</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>(2.999199231941019e-05, 0.0, 0.0, 0.0, 0.0, 0....</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>(0.1725115266724401, 0.010553827953049337, 0.0...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>(9.99733077313673e-06, 0.3683285955614219, 0.0...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>(0.0, 0.09603983437274898, 0.0, 3.216123081765...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>(0.00031784617147696776, 0.0, 0.0, 0.0, 0.0, 0...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>78861</th>\n","      <td>(0.0, 0.11609210748354272, 0.0, 2.563671882800...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>78862</th>\n","      <td>(6.894710878025331e-07, 0.037993780630977615, ...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>78863</th>\n","      <td>(0.00042678260334976794, 0.004221531181219735,...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>78864</th>\n","      <td>(0.0004388483473863123, 0.037993780630977615, ...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>78865</th>\n","      <td>(0.0, 0.12559055264128713, 0.0, 1.343566172682...</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>78866 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                features  label\n","0      (2.999199231941019e-05, 0.0, 0.0, 0.0, 0.0, 0....      4\n","1      (0.1725115266724401, 0.010553827953049337, 0.0...      5\n","2      (9.99733077313673e-06, 0.3683285955614219, 0.0...      4\n","3      (0.0, 0.09603983437274898, 0.0, 3.216123081765...      4\n","4      (0.00031784617147696776, 0.0, 0.0, 0.0, 0.0, 0...      3\n","...                                                  ...    ...\n","78861  (0.0, 0.11609210748354272, 0.0, 2.563671882800...      4\n","78862  (6.894710878025331e-07, 0.037993780630977615, ...      4\n","78863  (0.00042678260334976794, 0.004221531181219735,...      4\n","78864  (0.0004388483473863123, 0.037993780630977615, ...      4\n","78865  (0.0, 0.12559055264128713, 0.0, 1.343566172682...      4\n","\n","[78866 rows x 2 columns]"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["from pyspark.ml.feature import StandardScaler\n","\n","standard_scaler = StandardScaler(inputCol= 'vectorized_features', outputCol= 'features')\n","scaled_model = standard_scaler.fit(df_with_assembled_features)\n","df_with_scaled_features = scaled_model.transform(df_with_assembled_features)\n","\n","df_with_scaled_features.select(\"features\", \"label\").distinct().toPandas()"]},{"cell_type":"markdown","metadata":{},"source":["## Now combining all steps in a Pre-process Pipeline"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["import pyspark\n","from pyspark.sql import SparkSession, SQLContext\n","from pyspark.ml import Pipeline,Transformer\n","from pyspark.ml.feature import Imputer,StandardScaler,StringIndexer,OneHotEncoder, VectorAssembler\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","import numpy as np\n","\n","\n","# These are length cols so their values must be 0 or +ve\n","cols_non_negative = ['tcp_time_delta', 'tcp_len', 'mqtt_len', 'mqtt_proto_len', 'mqtt_willmsg_len', 'mqtt_willtopic_len']\n","\n","# nominal_cols = ['tcp_flags', 'mqtt_conack_flags', 'mqtt_conflags', 'mqtt_hdrflags']\n","# The other 2 are not useful --> (for more than 99% of the entries, they are 0)\n","# mqtt_hdrflags --> 37% of the entries are not in hex format but we will 1 hot encode it\n","nominal_cols = ['tcp_flags', 'mqtt_hdrflags']\n","\n","continous_cols = ['tcp_time_delta', 'tcp_len', 'mqtt_conack_flags_reserved', 'mqtt_conack_flags_sp',\\\n","                'mqtt_conflag_cleansess', 'mqtt_conflag_passwd', 'mqtt_conflag_qos', 'mqtt_conflag_reserved', \\\n","                'mqtt_conflag_retain', 'mqtt_conflag_uname', 'mqtt_conflag_willflag', 'mqtt_dupflag', \\\n","                'mqtt_kalive', 'mqtt_len', 'mqtt_msg', 'mqtt_msgid', 'mqtt_msgtype', 'mqtt_proto_len', \\\n","                'mqtt_qos', 'mqtt_retain', 'mqtt_sub_qos', 'mqtt_suback_qos', 'mqtt_willmsg', \\\n","                'mqtt_willmsg_len', 'mqtt_willtopic', 'mqtt_willtopic_len', 'mqtt_ver', 'mqtt_conack_val']\n","\n","def convert_string(s):\n","    return 0 if s == '0' else 1\n","\n","def convert_target_to_label(target):\n","    if target == 'slowite':\n","        return 0\n","    elif target == 'bruteforce':\n","        return 1\n","    elif target == 'flood':\n","        return 2\n","    elif target == 'malformed':\n","        return 3\n","    elif target == 'dos':\n","        return 4\n","    elif target == 'legitimate':\n","        return 5\n","    else:\n","        return 6\n","    \n","class RenameDatasetCols(Transformer):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def _transform(self, dataset):\n","        output_df = dataset\n","        all_cols = output_df.columns\n","        for column in all_cols:\n","            new_column = column.replace('.', '_')\n","            output_df = output_df.withColumnRenamed(column, new_column)\n","        # print(output_df.columns)\n","        return output_df\n","\n","class OutcomeCreator(Transformer):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def _transform(self, dataset):\n","        label_to_classes = udf(convert_target_to_label, IntegerType())\n","        output_df = dataset.withColumn('label', label_to_classes(dataset['target'])).drop('target')\n","        output_df = output_df.withColumn('label', output_df['label'].cast(DoubleType()))\n","        return output_df\n","    \n","class ConstraintChecker(Transformer):\n","    def __init__(self, columns_to_check = None):\n","        super().__init__()\n","\n","    def _transform(self, dataset):\n","        output_df = dataset\n","        for col_name in cols_non_negative:\n","            output_df = output_df.filter(output_df[col_name] >= 0)\n","        return output_df\n","    \n","class ColumnDropper(Transformer):\n","    def __init__(self, columns_to_drop = None):\n","        super().__init__()\n","        self.columns_to_drop = columns_to_drop\n","\n","    def _transform(self, dataset):\n","        output_df = dataset\n","        for col_name in self.columns_to_drop:\n","            if col_name in output_df.columns:\n","                output_df = output_df.drop(col_name)\n","        return output_df\n","    \n","def get_preprocess_pipeline():\n","\n","    # Stage where we rename the columns\n","    stage_column_renamer = RenameDatasetCols()\n","\n","    # Stage where we handle nominal values\n","    nominal_id_cols = [x+\"_index\" for x in nominal_cols]\n","    nominal_onehot_cols = [x+\"_encoded\" for x in nominal_cols]\n","    stage_nominal_indexer = StringIndexer(inputCols = nominal_cols, outputCols = nominal_id_cols )\n","\n","    # Stage where the index columns are further transformed using OneHotEncoder\n","    stage_nominal_onehot_encoder = OneHotEncoder(inputCols=nominal_id_cols, outputCols=nominal_onehot_cols)\n","\n","    # Stage where all relevant features are assembled into a vector (and dropping a few)\n","    feature_cols = continous_cols + nominal_onehot_cols\n","\n","    # These cols have only 1 unique value\n","    cols_single_val = ['mqtt_conack_flags_reserved', 'mqtt_conack_flags_sp', 'mqtt_conflag_qos', \\\n","                       'mqtt_conflag_reserved', 'mqtt_conflag_retain', 'mqtt_conflag_willflag', 'mqtt_sub_qos', \\\n","                        'mqtt_suback_qos', 'mqtt_willmsg', 'mqtt_willmsg_len', 'mqtt_willtopic', 'mqtt_willtopic_len']\n","    \n","    # Highly correlaterd columns\n","    cols_high_corr = ['mqtt_conflag_cleansess', 'mqtt_proto_len', 'mqtt_conflag_passwd', 'mqtt_len']\n","    \n","    # Not useful columns\n","    cols_not_useful = ['mqtt_msg']\n","\n","    # These are supposed to be in form 0x0000XX but > 99% are 0\n","    cols_hex_constraints_not_met = ['mqtt_conack_flags', 'mqtt_conflags']\n","\n","    # > 99% of the entries are 0\n","    cols_more_than_99_zero = ['mqtt_conack_val', 'mqtt_conflag_uname', 'mqtt_kalive', 'mqtt_protoname', 'mqtt_retain', 'mqtt_ver']\n","    \n","    cols_to_remove = cols_single_val + cols_high_corr + cols_not_useful + cols_hex_constraints_not_met + nominal_cols\\\n","                     + nominal_id_cols + cols_more_than_99_zero\n","    \n","    for col_name in cols_to_remove:\n","        if col_name in feature_cols:\n","            feature_cols.remove(col_name)\n","\n","    print(feature_cols)\n","    # Stage where we assemble all the features into a vector\n","\n","    stage_vector_assembler = VectorAssembler(inputCols=feature_cols, outputCol='vectorized_features')\n","\n","    # Stage where we scale the features\n","    stage_scaler = StandardScaler(inputCol= 'vectorized_features', outputCol= 'features')\n","\n","    # Stage where we create the label column\n","    stage_label_creator = OutcomeCreator()\n","\n","    # Removing all unnecessary columns, only keeping the 'features' and 'outcome' columns\n","    stage_column_dropper = ColumnDropper(columns_to_drop = continous_cols + ['vectorized_features'] + nominal_cols\\\n","                                         + nominal_id_cols + nominal_onehot_cols + cols_to_remove)\n","\n","    # Connecting the columns into a pipeline\n","    pipeline = Pipeline(stages = [stage_column_renamer, stage_nominal_indexer,\\\n","                                   stage_nominal_onehot_encoder, stage_vector_assembler, stage_scaler,\\\n","                                      stage_label_creator, stage_column_dropper])\n","    \n","    return pipeline    \n"]},{"cell_type":"markdown","metadata":{},"source":["### This PreProcess Pipeline will be used for preprocessing before feeding data into the model"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["['tcp_time_delta', 'tcp_len', 'mqtt_dupflag', 'mqtt_msgid', 'mqtt_msgtype', 'mqtt_qos', 'tcp_flags_encoded', 'mqtt_hdrflags_encoded']\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["mqtt_train_raw = spark.read.csv(\"gs://dataproc-staging-us-central1-159964990471-2n8oqiw8/train70_reduced.csv\" ,header=True, inferSchema= True)\n","mqtt_test_raw = spark.read.csv(\"gs://dataproc-staging-us-central1-159964990471-2n8oqiw8/test30_reduced.csv\", header=True, inferSchema=True)\n","\n","preprocess_pipeline = get_preprocess_pipeline()\n","preprocess_pipeline_model = preprocess_pipeline.fit(mqtt_train_raw)\n","\n","mqtt_train_df = preprocess_pipeline_model.transform(mqtt_train_raw)\n","mqtt_test_df = preprocess_pipeline_model.transform(mqtt_test_raw)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":2}